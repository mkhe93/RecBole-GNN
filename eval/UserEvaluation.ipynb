{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T14:14:23.821120Z",
     "start_time": "2025-01-14T14:14:23.814849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.5 (tags/v3.12.5:ff3bc82, Aug  6 2024, 20:45:27) [MSC v.1940 64 bit (AMD64)] on win32\n",
      "Project directory:  C:\\Users\\s8347434\\Documents\\RecBole-GNN\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# setting proper working directory\n",
    "PROJECT_DIRECTORY = Path(os.path.abspath('')).resolve().parents[0]\n",
    "sys.path.extend([str(PROJECT_DIRECTORY)])\n",
    "\n",
    "print(f'Python {sys.version} on {sys.platform}')\n",
    "print('Project directory: ', PROJECT_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f14768b905225241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T14:14:45.110471Z",
     "start_time": "2025-01-14T14:14:26.544812Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import seaborn as sns\n",
    "from recbole_gnn.config import Config\n",
    "from recbole_gnn.utils import create_dataset\n",
    "from recbole_gnn.data.dataset_metrics import GraphDatasetEvaluator\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import statsmodels.formula.api as sm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88dc2b65eb116ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists! Load file from ../eval/log/Benchmark/TotalEvaluationData-RO.csv\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'process_user_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Load the existing DataFrame\u001B[39;00m\n\u001B[0;32m      7\u001B[0m final_eval_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(file_path, sep\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 8\u001B[0m final_eval_df \u001B[38;5;241m=\u001B[39m \u001B[43mprocess_user_columns\u001B[49m(final_eval_df)\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Convert the user_popularity column back to dictionaries\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124muser_popularity\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m final_eval_df\u001B[38;5;241m.\u001B[39mcolumns:\n",
      "\u001B[1;31mNameError\u001B[0m: name 'process_user_columns' is not defined"
     ]
    }
   ],
   "source": [
    "file_path = \"../eval/log/Benchmark/TotalEvaluationData-RO.csv\"\n",
    "if not os.path.isfile(file_path):\n",
    "    print(\"File does not exist, please run all the lines above..\")\n",
    "else:\n",
    "    print(f\"File exists! Load file from {file_path}\")\n",
    "    # Load the existing DataFrame\n",
    "    final_eval_df = pd.read_csv(file_path, sep='\\t')\n",
    "    final_eval_df = process_user_columns(final_eval_df)\n",
    "\n",
    "    # Convert the user_popularity column back to dictionaries\n",
    "    if 'user_popularity' in final_eval_df.columns:\n",
    "        final_eval_df['user_popularity'] = final_eval_df['user_popularity'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994366b25c872feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_characteristics = pd.read_csv(\"../eval/log/Dataset/dataset_eval.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30158e6d02831ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_characteristics['density'] = 1 - dataset_characteristics['sparsity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87fdfd0e23ff0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through columns that start with \"average_clustering\"\n",
    "for col in dataset_characteristics.columns:\n",
    "    if col.startswith('average_clustering') or col.startswith('density'):\n",
    "        # Calculate log10 and create a new column with \"_log\" suffix\n",
    "        dataset_characteristics[f\"{col}_log\"] = np.log10(dataset_characteristics[col])\n",
    "\n",
    "dataset_characteristics['dataset'] = dataset_characteristics['dataset'].str.extract(r'-(\\d+)$').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185537581857c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_characteristics.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d674dfccfba95c17",
   "metadata": {},
   "source": [
    "## Read and Transform Benchark Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d25f796fa5fe193e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T14:14:46.607986Z",
     "start_time": "2025-01-14T14:14:46.464123Z"
    }
   },
   "outputs": [],
   "source": [
    "#als_df = pd.read_csv(\"log/Benchmark/old/ALS-Benchmark-RO.csv\", sep=\"\\t\")\n",
    "asym_user_df = pd.read_csv(\"log/Benchmark/old/RO/AsymKNNUser-Benchmark-RO.csv\", sep=\"\\t\")\n",
    "asym_item_df = pd.read_csv(\"log/Benchmark/old/RO/AsymKNNItem-Benchmark-RO.csv\", sep=\"\\t\")\n",
    "#bpr_df = pd.read_csv(\"log/Benchmark/old/BPR-Benchmark-RO.csv\", sep=\"\\t\")\n",
    "ngcf_df = pd.read_csv(\"log/Benchmark/RO/NGCF-Benchmark-RO.csv\", sep=\"\\t\")\n",
    "lightgcn_df = pd.read_csv(\"log/Benchmark/RO/LightGCN-Benchmark-RO.csv\", sep=\"\\t\")\n",
    "sgl_df = pd.read_csv(\"log/Benchmark/RO/SGL-Benchmark-RO.csv\", sep=\"\\t\")\n",
    "xsimgcl_df = pd.read_csv(\"log/Benchmark/RO/XSimGCL-Benchmark-RO.csv\", sep=\"\\t\")\n",
    "pop_df = pd.read_csv(\"log/Benchmark/RO/Pop-Benchmark-RO.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c22fa6dc2981161a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T14:14:47.193208Z",
     "start_time": "2025-01-14T14:14:47.176587Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_df = pd.concat([pop_df, asym_user_df, asym_item_df, ngcf_df, lightgcn_df, sgl_df, xsimgcl_df], ignore_index=True)\n",
    "overall_df['dataset'] = overall_df['dataset'].str.extract(r'-(\\d+)$').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e42ac7f840d0406",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T14:14:53.034402Z",
     "start_time": "2025-01-14T14:14:53.027135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                                                                      Pop\n",
      "dataset                                                                      2\n",
      "precision@10                                                            0.0313\n",
      "hit@10                                                                   0.202\n",
      "mrr@10                                                                  0.0806\n",
      "ndcg@10                                                                 0.0382\n",
      "map@10                                                                  0.0162\n",
      "itemcoverage@10                                                         0.0018\n",
      "averagepopularity@10                                                   93.7833\n",
      "tailpercentage@10                                                          0.0\n",
      "best_user_precision@[10]     [{'206': '0.6'}, {'157': '0.5'}, {'428': '0.5'...\n",
      "best_user_hit@[10]           [{'184': '1'}, {'461': '1'}, {'460': '1'}, {'7...\n",
      "best_user_mrr@[10]           [{'184': '1.0'}, {'137': '1.0'}, {'70': '1.0'}...\n",
      "best_user_ndcg@[10]          [{'206': '0.6969'}, {'155': '0.5811'}, {'470':...\n",
      "best_user_map@[10]           [{'206': '0.5264'}, {'155': '0.3671'}, {'184':...\n",
      "worst_user_precision@[10]    [{'1': '0.0'}, {'671': '0.0'}, {'673': '0.0'},...\n",
      "worst_user_hit@[10]          [{'1': '0'}, {'671': '0'}, {'673': '0'}, {'676...\n",
      "worst_user_mrr@[10]          [{'1': '0.0'}, {'671': '0.0'}, {'673': '0.0'},...\n",
      "worst_user_ndcg@[10]         [{'1': '0.0'}, {'671': '0.0'}, {'673': '0.0'},...\n",
      "worst_user_map@[10]          [{'1': '0.0'}, {'671': '0.0'}, {'673': '0.0'},...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(overall_df.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5ea03ce30be2950",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T14:14:53.532167Z",
     "start_time": "2025-01-14T14:14:53.525876Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to process columns starting with 'best_user_' or 'worst_user_'\n",
    "def process_user_columns(df):\n",
    "    for col in df.columns:\n",
    "        if col.startswith('best_user_') or col.startswith('worst_user_'):\n",
    "            # Apply transformation for each row in the selected columns\n",
    "            df[col] = df[col].apply(ast.literal_eval)            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f03356cc318fd9a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T14:14:55.473253Z",
     "start_time": "2025-01-14T14:14:54.088293Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_df = process_user_columns(overall_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5471bf4837659fb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T14:14:55.493781Z",
     "start_time": "2025-01-14T14:14:55.483253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [{'937': '0.8'}, {'24': '0.5'}, {'743': '0.5'}...\n",
      "1    [{'206': '0.6'}, {'157': '0.5'}, {'428': '0.5'...\n",
      "Name: best_user_precision@[10], dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(overall_df.head(2)['best_user_precision@[10]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f82e3babf48ce",
   "metadata": {},
   "source": [
    "#### Calculate the best and worst users topological characterisitcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fb511913dee3eb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:31:16.878220Z",
     "start_time": "2025-01-14T16:31:16.863743Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_users_topological_chars(data, file_path, num_datasets):    \n",
    "    \n",
    "    dataset_eval_list = []\n",
    "    for i in tqdm(range(113,114), total=num_datasets, unit='datasets'):\n",
    "        # mapping recbole ID -> local ID (as recbole resets the index after filtering the datasets)\n",
    "        config = Config(model=\"BPR\", dataset=f\"real-life-atomic-100000-{i+1}\", config_file_list=[\"config_files/datasets.yaml\"])\n",
    "        dataset = create_dataset(config)\n",
    "\n",
    "        print(i)\n",
    "\n",
    "        # Extract unique user IDs from best_user_ and worst_user_ columns\n",
    "        best_user_ids = set()  # Use a set to ensure uniqueness\n",
    "        worst_user_ids = set()  # Use a set to ensure uniqueness\n",
    "        for index, row in data[data['dataset']==i+1].iterrows():\n",
    "            for col in data.columns:\n",
    "                if col.startswith('best_user_'):\n",
    "                    # Extract user IDs from the list of dictionaries\n",
    "                    for entry in row[col]:  # Assuming each entry is a list of dictionaries\n",
    "                        best_user_ids.add(int(list(entry.keys())[0]))  # Add user ID (the key) to the set\n",
    "                if col.startswith('worst_user_'):\n",
    "                    # Extract user IDs from the list of dictionaries\n",
    "                    for entry in row[col]:  # Assuming each entry is a list of dictionaries\n",
    "                        worst_user_ids.add(int(list(entry.keys())[0]))  # Add user ID (the key) to the set\n",
    "\n",
    "        print(best_user_ids)\n",
    "        print(worst_user_ids)\n",
    "\n",
    "        # calculate dataset metrics\n",
    "        dataset_evaluator = GraphDatasetEvaluator(config, dataset)\n",
    "        # some metrics need a connected graph and thus drops nodes which are in smallest partition\n",
    "        #if not dataset_evaluator.connected:\n",
    "        #    continue\n",
    "        dataset_eval_dict = {\"dataset\": i+1}\n",
    "        dataset_eval_dict.update(dataset_evaluator.evaluate_best_worst_users(best_user_ids, worst_user_ids))\n",
    "        dataset_eval_list.append(dataset_eval_dict)\n",
    "\n",
    "        df = pd.DataFrame(dataset_eval_list)\n",
    "        df.to_csv(file_path, sep='\\t', index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d5dfa0a0315c883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:53:32.793740Z",
     "start_time": "2025-01-14T16:46:44.939308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist, calculate all user's topology characteristics for each dataset..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?datasets/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n",
      "{1, 524, 1038, 534, 30, 38, 551, 567, 569, 572, 576, 579, 580, 70, 583, 584, 585, 77, 592, 595, 599, 602, 605, 608, 610, 612, 613, 615, 616, 620, 623, 1136, 632, 633, 122, 637, 638, 640, 643, 645, 646, 648, 650, 652, 660, 159, 161, 677, 167, 1193, 683, 1196, 687, 688, 699, 187, 189, 190, 723, 215, 749, 750, 751, 752, 753, 754, 242, 756, 757, 758, 760, 761, 762, 763, 768, 770, 771, 263, 775, 776, 778, 780, 781, 782, 783, 784, 785, 787, 788, 789, 276, 791, 1307, 796, 797, 296, 298, 299, 815, 817, 819, 310, 835, 362, 365, 376, 892, 393, 917, 410, 425, 430, 444, 964, 969, 458, 976, 977, 472, 984, 994}\n",
      "{513, 515, 1028, 1029, 516, 1031, 518, 1033, 1034, 523, 1035, 1037, 1040, 530, 532, 535, 536, 538, 539, 1052, 540, 543, 1056, 545, 546, 547, 1058, 1061, 1055, 1064, 557, 1073, 562, 564, 1077, 566, 570, 572, 574, 577, 1089, 581, 1097, 587, 588, 1099, 1102, 590, 592, 594, 1107, 597, 598, 1109, 600, 601, 1111, 603, 604, 1116, 608, 1121, 609, 611, 612, 1120, 1127, 619, 1134, 1137, 1149, 639, 641, 642, 1157, 1158, 1159, 1162, 1165, 1166, 1167, 1174, 664, 665, 1178, 1179, 1180, 1184, 1190, 691, 695, 1208, 696, 698, 703, 704, 705, 1215, 707, 708, 710, 712, 713, 714, 1224, 716, 717, 1227, 1234, 744, 746, 747, 748, 759, 763, 764, 765, 766, 767, 768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 787, 790, 794, 1320, 820, 826, 833, 322, 323, 324, 325, 842, 844, 846, 849, 856, 351, 352, 353, 354, 356, 357, 371, 373, 375, 378, 384, 897, 385, 896, 388, 389, 902, 391, 903, 392, 394, 395, 390, 397, 398, 396, 912, 399, 402, 403, 404, 400, 406, 408, 409, 419, 420, 423, 424, 426, 427, 940, 941, 943, 944, 945, 434, 436, 439, 442, 443, 445, 446, 447, 448, 450, 451, 460, 974, 975, 462, 467, 469, 470, 983, 986, 475, 987, 480, 482, 488, 489, 490, 492, 493, 494, 495, 496, 497, 498, 499, 500, 503, 506, 510, 511}\n",
      "GraphDatasetEvaluator: the graph is not connected.\n",
      "GraphDatasetEvaluator: the graph is not connected.\n",
      "GraphDatasetEvaluator: the graph is not connected. Building the connected subgraph.\n",
      "The disconnected partitions:  [{1031, 15111, 15113, 14862, 14998, 15002, 15135, 14624, 15141, 15025, 15026, 15041, 15169, 15047, 15048, 15057, 14941, 15071, 15077, 14954, 14973}]\n",
      "GraphDatasetEvaluator: graph is connected.\n",
      "GraphDatasetEvaluator: graph characteristics\n",
      " nodes: 17702\n",
      " edges: 74959\n",
      " user nodes: 1319\n",
      " item nodes: 16383\n",
      "GraphDatasetEvaluator: 2 users removed\n",
      "GraphDatasetEvaluator: 21 items removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [06:59<?, ?datasets/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Key 1031 not found'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(file_path):\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFile does not exist, calculate all user\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms topology characteristics for each dataset..\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m     user_topologies_df \u001B[38;5;241m=\u001B[39m \u001B[43mget_users_topological_chars\u001B[49m\u001B[43m(\u001B[49m\u001B[43moverall_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_datasets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFile exists! Load file from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[12], line 34\u001B[0m, in \u001B[0;36mget_users_topological_chars\u001B[1;34m(data, file_path, num_datasets)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m# some metrics need a connected graph and thus drops nodes which are in smallest partition\u001B[39;00m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m#if not dataset_evaluator.connected:\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m#    continue\u001B[39;00m\n\u001B[0;32m     33\u001B[0m dataset_eval_dict \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\"\u001B[39m: i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m}\n\u001B[1;32m---> 34\u001B[0m dataset_eval_dict\u001B[38;5;241m.\u001B[39mupdate(\u001B[43mdataset_evaluator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate_best_worst_users\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbest_user_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mworst_user_ids\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     35\u001B[0m dataset_eval_list\u001B[38;5;241m.\u001B[39mappend(dataset_eval_dict)\n\u001B[0;32m     37\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(dataset_eval_list)\n",
      "File \u001B[1;32m~\\Documents\\RecBole-GNN\\recbole_gnn\\data\\dataset_metrics.py:601\u001B[0m, in \u001B[0;36mGraphDatasetEvaluator.evaluate_best_worst_users\u001B[1;34m(self, best_user_nodes, worst_user_nodes)\u001B[0m\n\u001B[0;32m    596\u001B[0m best_user_to_community_index \u001B[38;5;241m=\u001B[39m {user: user_to_community_map\u001B[38;5;241m.\u001B[39mget(user, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m user \u001B[38;5;129;01min\u001B[39;00m best_user_nodes}\n\u001B[0;32m    597\u001B[0m worst_user_to_community_index \u001B[38;5;241m=\u001B[39m {user: user_to_community_map\u001B[38;5;241m.\u001B[39mget(user, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m user \u001B[38;5;129;01min\u001B[39;00m worst_user_nodes}\n\u001B[0;32m    599\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[0;32m    600\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdegree_assort_best_users\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdegree_assortativity(best_user_nodes),\n\u001B[1;32m--> 601\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdegree_assort_worst_users\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdegree_assortativity\u001B[49m\u001B[43m(\u001B[49m\u001B[43mworst_user_nodes\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m    602\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maverage_clustering_coef_dot_best_users\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcalculate_average_clustering(method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdot\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    603\u001B[0m                                                        nodes\u001B[38;5;241m=\u001B[39mbest_user_nodes,\n\u001B[0;32m    604\u001B[0m                                                        precomputed_clustering\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprecomputed_clustering),\n\u001B[0;32m    605\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maverage_clustering_coef_dot_worst_users\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcalculate_average_clustering(method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdot\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    606\u001B[0m                                                         nodes\u001B[38;5;241m=\u001B[39mworst_user_nodes,\n\u001B[0;32m    607\u001B[0m                                                         precomputed_clustering\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprecomputed_clustering),\n\u001B[0;32m    608\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclustering_coefficients_best_users\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclustering(mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdot\u001B[39m\u001B[38;5;124m'\u001B[39m, nodes\u001B[38;5;241m=\u001B[39mbest_user_nodes),\n\u001B[0;32m    609\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclustering_coefficients_worst_users\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclustering(mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdot\u001B[39m\u001B[38;5;124m'\u001B[39m, nodes\u001B[38;5;241m=\u001B[39mworst_user_nodes),\n\u001B[0;32m    610\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbest_user_to_community\u001B[39m\u001B[38;5;124m'\u001B[39m: best_user_to_community_index,\n\u001B[0;32m    611\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mworst_user_to_community\u001B[39m\u001B[38;5;124m'\u001B[39m: worst_user_to_community_index,\n\u001B[0;32m    612\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcommunities\u001B[39m\u001B[38;5;124m'\u001B[39m: communities\n\u001B[0;32m    613\u001B[0m }\n",
      "File \u001B[1;32m~\\Documents\\RecBole-GNN\\recbole_gnn\\data\\dataset_metrics.py:161\u001B[0m, in \u001B[0;36mGraphDatasetEvaluator.degree_assortativity\u001B[1;34m(self, nodes)\u001B[0m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdegree_assortativity\u001B[39m(\u001B[38;5;28mself\u001B[39m, nodes):\n\u001B[1;32m--> 161\u001B[0m     graph \u001B[38;5;241m=\u001B[39m \u001B[43mbipartite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprojected_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbipartite_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    162\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m networkx\u001B[38;5;241m.\u001B[39mdegree_pearson_correlation_coefficient(graph, nodes\u001B[38;5;241m=\u001B[39mnodes)\n",
      "File \u001B[1;32m<class 'networkx.utils.decorators.argmap'> compilation 52:3\u001B[0m, in \u001B[0;36margmap_projected_graph_49\u001B[1;34m(B, nodes, multigraph, backend, **backend_kwargs)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbz2\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcollections\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgzip\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01minspect\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mitertools\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\RecBole-GNN\\.venv\\Lib\\site-packages\\networkx\\utils\\backends.py:967\u001B[0m, in \u001B[0;36m_dispatchable.__call__\u001B[1;34m(self, backend, *args, **kwargs)\u001B[0m\n\u001B[0;32m    965\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m backend \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m backend \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnetworkx\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    966\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbackend\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m backend is not installed\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 967\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43morig_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    969\u001B[0m \u001B[38;5;66;03m# Use `backend_name` in this function instead of `backend`.\u001B[39;00m\n\u001B[0;32m    970\u001B[0m \u001B[38;5;66;03m# This is purely for aesthetics and to make it easier to search for this\u001B[39;00m\n\u001B[0;32m    971\u001B[0m \u001B[38;5;66;03m# variable since \"backend\" is used in many comments and log/error messages.\u001B[39;00m\n\u001B[0;32m    972\u001B[0m backend_name \u001B[38;5;241m=\u001B[39m backend\n",
      "File \u001B[1;32m~\\Documents\\RecBole-GNN\\.venv\\Lib\\site-packages\\networkx\\algorithms\\bipartite\\projection.py:105\u001B[0m, in \u001B[0;36mprojected_graph\u001B[1;34m(B, nodes, multigraph)\u001B[0m\n\u001B[0;32m    103\u001B[0m         G \u001B[38;5;241m=\u001B[39m nx\u001B[38;5;241m.\u001B[39mGraph()\n\u001B[0;32m    104\u001B[0m G\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mupdate(B\u001B[38;5;241m.\u001B[39mgraph)\n\u001B[1;32m--> 105\u001B[0m \u001B[43mG\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_nodes_from\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnodes\u001B[49m\u001B[43m[\u001B[49m\u001B[43mn\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m u \u001B[38;5;129;01min\u001B[39;00m nodes:\n\u001B[0;32m    107\u001B[0m     nbrs2 \u001B[38;5;241m=\u001B[39m {v \u001B[38;5;28;01mfor\u001B[39;00m nbr \u001B[38;5;129;01min\u001B[39;00m B[u] \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m B[nbr] \u001B[38;5;28;01mif\u001B[39;00m v \u001B[38;5;241m!=\u001B[39m u}\n",
      "File \u001B[1;32m~\\Documents\\RecBole-GNN\\.venv\\Lib\\site-packages\\networkx\\classes\\graph.py:634\u001B[0m, in \u001B[0;36mGraph.add_nodes_from\u001B[1;34m(self, nodes_for_adding, **attr)\u001B[0m\n\u001B[0;32m    573\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21madd_nodes_from\u001B[39m(\u001B[38;5;28mself\u001B[39m, nodes_for_adding, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mattr):\n\u001B[0;32m    574\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Add multiple nodes.\u001B[39;00m\n\u001B[0;32m    575\u001B[0m \n\u001B[0;32m    576\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;124;03m    >>> G.add_nodes_from(list(n + 1 for n in G.nodes))\u001B[39;00m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 634\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnodes_for_adding\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m    635\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mtry\u001B[39;49;00m\u001B[43m:\u001B[49m\n\u001B[0;32m    636\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewnode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_node\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\RecBole-GNN\\.venv\\Lib\\site-packages\\networkx\\algorithms\\bipartite\\projection.py:105\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    103\u001B[0m         G \u001B[38;5;241m=\u001B[39m nx\u001B[38;5;241m.\u001B[39mGraph()\n\u001B[0;32m    104\u001B[0m G\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mupdate(B\u001B[38;5;241m.\u001B[39mgraph)\n\u001B[1;32m--> 105\u001B[0m G\u001B[38;5;241m.\u001B[39madd_nodes_from((n, \u001B[43mB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnodes\u001B[49m\u001B[43m[\u001B[49m\u001B[43mn\u001B[49m\u001B[43m]\u001B[49m) \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m nodes)\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m u \u001B[38;5;129;01min\u001B[39;00m nodes:\n\u001B[0;32m    107\u001B[0m     nbrs2 \u001B[38;5;241m=\u001B[39m {v \u001B[38;5;28;01mfor\u001B[39;00m nbr \u001B[38;5;129;01min\u001B[39;00m B[u] \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m B[nbr] \u001B[38;5;28;01mif\u001B[39;00m v \u001B[38;5;241m!=\u001B[39m u}\n",
      "File \u001B[1;32m~\\Documents\\RecBole-GNN\\.venv\\Lib\\site-packages\\networkx\\classes\\reportviews.py:196\u001B[0m, in \u001B[0;36mNodeView.__getitem__\u001B[1;34m(self, n)\u001B[0m\n\u001B[0;32m    191\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(n, \u001B[38;5;28mslice\u001B[39m):\n\u001B[0;32m    192\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m nx\u001B[38;5;241m.\u001B[39mNetworkXError(\n\u001B[0;32m    193\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not support slicing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    194\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtry list(G.nodes)[\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn\u001B[38;5;241m.\u001B[39mstart\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn\u001B[38;5;241m.\u001B[39mstop\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn\u001B[38;5;241m.\u001B[39mstep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    195\u001B[0m     )\n\u001B[1;32m--> 196\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nodes\u001B[49m\u001B[43m[\u001B[49m\u001B[43mn\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\RecBole-GNN\\.venv\\Lib\\site-packages\\networkx\\classes\\coreviews.py:305\u001B[0m, in \u001B[0;36mFilterAtlas.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_atlas \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mNODE_OK(key):\n\u001B[0;32m    304\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_atlas[key]\n\u001B[1;32m--> 305\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKey \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'Key 1031 not found'"
     ]
    }
   ],
   "source": [
    "# HINT: takes approx. 5h\n",
    "file_path = \"log/Dataset/user_topological_characteristics3.csv\"\n",
    "if not os.path.isfile(file_path):\n",
    "    print(\"File does not exist, calculate all user's topology characteristics for each dataset..\")\n",
    "    user_topologies_df = get_users_topological_chars(overall_df, file_path, num_datasets=1)\n",
    "else:\n",
    "    print(f\"File exists! Load file from {file_path}\")\n",
    "    user_topologies_df = pd.read_csv(file_path, sep='\\t')\n",
    "    user_topologies_df = process_user_columns(user_topologies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ce87e8cdc6620c",
   "metadata": {},
   "source": [
    "#### Translate the userIDs into the userIDs out of the original dataset\n",
    "- global ID: the userID which holds through all splits\n",
    "- local ID: the userID which is only valid within one split\n",
    "- recbole ID: the userID which is assigned after the filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b142f0f925a88e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_userids(data, num_rows):      \n",
    "    # Extract columns ending with @[10]\n",
    "    columns_to_process = [col for col in data.columns if col.endswith(\"@[10]\")]\n",
    "    \n",
    "    for index, row in tqdm(data.iloc[:num_rows].iterrows(), total=num_rows, unit='rows'):\n",
    "        # configurations initialization\n",
    "        FILENAME = PROJECT_DIRECTORY / f\"asset/data/real-life-atomic-splits/real-life-atomic-100000-{row['dataset']}/real-life-atomic-100000-{row['dataset']}.inter\"\n",
    "        db = pd.read_csv(FILENAME, sep=\"\\t\", encoding=\"utf-8\")\n",
    "        \n",
    "        # mapping recbole ID -> local ID (as recbole resets the index after filtering the datasets)\n",
    "        config = Config(model=\"BPR\", dataset=f\"real-life-atomic-100000-{row['dataset']}\", config_file_list=[\"config_files/datasets.yaml\"])\n",
    "        dataset = create_dataset(config)\n",
    "        flipped_dict = {v: k for k, v in dataset.field2token_id['user_id'].items()}\n",
    "                \n",
    "        # mapping local ID -> global ID\n",
    "        translation_dict = dict(zip(db[\"user_id:token\"], db[\"userID:token\"]))\n",
    "                \n",
    "        # Process each column\n",
    "        for col in columns_to_process:\n",
    "            # Parse the string entries and extract the user IDs\n",
    "            #print(row['Model'], row['dataset'], col)\n",
    "            new_entry = [\n",
    "                    {translation_dict[int(flipped_dict[int(list(entry.keys())[0])])] : float(list(entry.values())[0])}\n",
    "                    for entry in row[col]\n",
    "                ]\n",
    "            data.at[index, col] = new_entry\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579434b386ecc44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HINT: takes approx. 20-30min.\n",
    "file_path = \"log/Benchmark/Overall-Benchmark-RO.csv\"\n",
    "if not os.path.isfile(file_path):\n",
    "    print(\"File does not exist, calculate all user's popularity for each dataset..\")\n",
    "    overall_df = translate_userids(overall_df, num_rows=overall_df.shape[0])\n",
    "    overall_df.to_csv(file_path, sep='\\t', index=False)\n",
    "else:\n",
    "    print(f\"File exists! Load file from {file_path}\")\n",
    "    overall_df = pd.read_csv(file_path, sep='\\t')\n",
    "    overall_df = process_user_columns(overall_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70f7b17f3ec4b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(overall_df.head(2)['best_user_precision@[10]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213cd19c56113ade",
   "metadata": {},
   "source": [
    "#### Calculate the popularity of each user's interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1be446dcddf9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_users_popularity(num_datasets):    \n",
    "    \n",
    "    # Initialize DataFrame with pre-defined size and columns\n",
    "    df = pd.DataFrame({'dataset': range(1, num_datasets + 1)})        \n",
    "    df['user_popularity'] = [{} for _ in range(num_datasets)]     \n",
    "    \n",
    "    # Loop through each dataset and compute user popularity\n",
    "    for i in tqdm(range(num_datasets)):\n",
    "        FILENAME = PROJECT_DIRECTORY / f\"asset/data/real-life-atomic-splits/real-life-atomic-100000-{i+1}/real-life-atomic-100000-{i+1}.inter\"\n",
    "        db = pd.read_csv(FILENAME, sep=\"\\t\", encoding=\"utf-8\")\n",
    "        \n",
    "        # Filter users with less than 20 interactions\n",
    "        db['interaction_count'] = db.groupby(\"userID:token\")[\"itemID:token\"].transform('count')\n",
    "        filtered_df = db[db['interaction_count'] >= 20].copy()\n",
    "        \n",
    "        # Calculate item popularity\n",
    "        item_popularity = filtered_df.groupby(\"itemID:token\")[\"userID:token\"].nunique()\n",
    "        \n",
    "        # Map item popularity back to filtered_df safely\n",
    "        filtered_df.loc[:, 'item_popularity'] = filtered_df[\"itemID:token\"].map(item_popularity)\n",
    "        \n",
    "        # Compute user average popularity\n",
    "        user_avg_popularity = filtered_df.groupby(\"userID:token\")['item_popularity'].agg(['mean', 'median'])\n",
    "        \n",
    "        # Compute user popularity dictionary\n",
    "        all_users_popularity_dict = {\n",
    "            user_id: (row['mean'], row['median']) \n",
    "            for user_id, row in user_avg_popularity.iterrows()\n",
    "        }\n",
    "        \n",
    "        # Assign the dictionary to the DataFrame\n",
    "        df.at[i,'user_popularity'] = all_users_popularity_dict\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6dd463b88d3550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HINT: takes approx.\n",
    "file_path = \"../asset/data/real-life-atomic-splits/user_popularity.csv\"\n",
    "if not os.path.isfile(file_path):\n",
    "    print(\"File does not exist, calculate all user's popularity for each dataset..\")\n",
    "    popularity_dict = get_all_users_popularity(num_datasets=177)\n",
    "    popularity_dict.to_csv(file_path, sep='\\t', index=False)\n",
    "else:\n",
    "    print(f\"File exists! Load file from {file_path}\")\n",
    "    # Load the existing DataFrame\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    # Convert the user_popularity column back to dictionaries\n",
    "    if 'user_popularity' in df.columns:\n",
    "        df['user_popularity'] = df['user_popularity'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c692c71d466bad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(popularity_dict.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107c0409b49a4037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_popularity(data, all_users_popularity_dict, num_rows):\n",
    "    \n",
    "    df = data.copy()\n",
    "    \n",
    "    # Initialize new columns with empty lists\n",
    "    df['best_users_mean_popularity_dict'] = [{} for _ in range(len(df))]\n",
    "    df['best_users_mean_popularity_mean'] = [{} for _ in range(len(df))]\n",
    "    df['best_users_mean_popularity_max'] = [{} for _ in range(len(df))]\n",
    "    df['best_users_mean_popularity_min'] = [{} for _ in range(len(df))]    \n",
    "    df['best_users_median_popularity_dict'] = [{} for _ in range(len(df))]\n",
    "    df['best_users_median_popularity_mean'] = [{} for _ in range(len(df))]\n",
    "    df['best_users_median_popularity_max'] = [{} for _ in range(len(df))]\n",
    "    df['best_users_median_popularity_min'] = [{} for _ in range(len(df))]\n",
    "    df['best_users_node_degree'] = [{} for _ in range(len(df))]\n",
    "    df['best_users_node_degree_mean'] = [{} for _ in range(len(df))]\n",
    "    df['best_users_node_degree_median'] = [{} for _ in range(len(df))]\n",
    "    df['best_users_node_degree_min'] = [{} for _ in range(len(df))]\n",
    "    df['best_users_node_degree_max'] = [{} for _ in range(len(df))]\n",
    "\n",
    "    df['worst_users_mean_popularity_dict'] = [{} for _ in range(len(df))]\n",
    "    df['worst_users_mean_popularity_mean'] = [{} for _ in range(len(df))]\n",
    "    df['worst_users_mean_popularity_max'] = [{} for _ in range(len(df))]\n",
    "    df['worst_users_mean_popularity_min'] = [{} for _ in range(len(df))]    \n",
    "    df['worst_users_median_popularity_dict'] = [{} for _ in range(len(df))]\n",
    "    df['worst_users_median_popularity_mean'] = [{} for _ in range(len(df))]\n",
    "    df['worst_users_median_popularity_max'] = [{} for _ in range(len(df))]\n",
    "    df['worst_users_median_popularity_min'] = [{} for _ in range(len(df))]\n",
    "    df['worst_users_node_degree'] = [{} for _ in range(len(df))]\n",
    "    df['worst_users_node_degree_mean'] = [{} for _ in range(len(df))]\n",
    "    df['worst_users_node_degree_median'] = [{} for _ in range(len(df))]\n",
    "    df['worst_users_node_degree_min'] = [{} for _ in range(len(df))]\n",
    "    df['worst_users_node_degree_max'] = [{} for _ in range(len(df))]\n",
    "\n",
    "    df['all_users_median_popularity_mean'] = [{} for _ in range(len(df))]\n",
    "    df['all_users_median_popularity_max'] = [{} for _ in range(len(df))]\n",
    "    df['all_users_median_popularity_min'] = [{} for _ in range(len(df))]\n",
    "    df['all_users_node_degree_mean'] = [{} for _ in range(len(df))]\n",
    "    df['all_users_median_node_degree_median'] = [{} for _ in range(len(df))]\n",
    "    df['all_users_node_degree_max'] = [{} for _ in range(len(df))]\n",
    "    df['all_users_node_degree_min'] = [{} for _ in range(len(df))]    \n",
    "     \n",
    "    # Loop through each row\n",
    "    for index, row in tqdm(df.iloc[:num_rows].iterrows(), total=num_rows, unit='rows'):\n",
    "\n",
    "        # configurations initialization\n",
    "        FILENAME = PROJECT_DIRECTORY / f\"asset/data/real-life-atomic-splits/real-life-atomic-100000-{row['dataset']}/real-life-atomic-100000-{row['dataset']}.inter\"\n",
    "        db = pd.read_csv(FILENAME, sep=\"\\t\", encoding=\"utf-8\")\n",
    "        \n",
    "        # Filter users with less than 20 node_degree\n",
    "        db['interaction_count'] = db.groupby(\"userID:token\")[\"itemID:token\"].transform('count')\n",
    "        filtered_df = db[db['interaction_count'] >= 20].copy()\n",
    "        all_users_node_degree_dict = filtered_df.groupby(\"userID:token\")['interaction_count'].first()\n",
    "                        \n",
    "        # Extract unique user IDs from best_user_ and worst_user_ columns\n",
    "        best_user_ids = set()  # Use a set to ensure uniqueness\n",
    "        worst_user_ids = set()  # Use a set to ensure uniqueness\n",
    "        for col in df.columns:\n",
    "            if col.startswith('best_user_'):\n",
    "                # Extract user IDs from the list of dictionaries\n",
    "                for entry in row[col]:  # Assuming each entry is a list of dictionaries\n",
    "                    best_user_ids.add(int(list(entry.keys())[0]))  # Add user ID (the key) to the set\n",
    "            if col.startswith('worst_user_'):\n",
    "                # Extract user IDs from the list of dictionaries\n",
    "                for entry in row[col]:  # Assuming each entry is a list of dictionaries\n",
    "                    worst_user_ids.add(int(list(entry.keys())[0]))  # Add user ID (the key) to the set\n",
    "                                         \n",
    "        # Prepare best users\n",
    "        best_users_mean_popularity_dict = {user_id: all_users_popularity_dict.loc[row['dataset']-1,'user_popularity'][user_id][0] for user_id in best_user_ids}\n",
    "        best_users_median_popularity_dict = {user_id: all_users_popularity_dict.loc[row['dataset']-1,'user_popularity'][user_id][1] for user_id in best_user_ids}\n",
    "        best_users_node_degree_dict = {user_id: all_users_node_degree_dict[user_id] for user_id in best_user_ids}     \n",
    "        best_users_mean_values_list = list(best_users_mean_popularity_dict.values())\n",
    "        best_users_median_values_list = list(best_users_median_popularity_dict.values())\n",
    "        best_users_node_degree_list = list(best_users_node_degree_dict.values())\n",
    "\n",
    "        worst_users_mean_popularity_dict = {user_id: all_users_popularity_dict.loc[row['dataset']-1,'user_popularity'][user_id][0] for user_id in worst_user_ids}\n",
    "        worst_users_median_popularity_dict = {user_id: all_users_popularity_dict.loc[row['dataset']-1,'user_popularity'][user_id][1] for user_id in worst_user_ids}\n",
    "        worst_users_node_degree_dict = {user_id: all_users_node_degree_dict[user_id] for user_id in worst_user_ids}     \n",
    "        worst_users_mean_values_list = list(worst_users_mean_popularity_dict.values())\n",
    "        worst_users_median_values_list = list(worst_users_median_popularity_dict.values())\n",
    "        worst_users_node_degree_list = list(worst_users_node_degree_dict.values())\n",
    "        \n",
    "        all_users_mean_values_list = [entry[0] for entry in list(all_users_popularity_dict.loc[row['dataset']-1,'user_popularity'].values())]\n",
    "        all_users_median_values_list = [entry[1] for entry in list(all_users_popularity_dict.loc[row['dataset']-1,'user_popularity'].values())]\n",
    "\n",
    "        # Assign\n",
    "        df.at[index, 'best_users_mean_popularity_dict'] = best_users_mean_popularity_dict\n",
    "        df.at[index, 'best_users_mean_popularity_mean'] = np.mean(best_users_mean_values_list)\n",
    "        df.at[index, 'best_users_mean_popularity_max'] = np.max(best_users_mean_values_list)\n",
    "        df.at[index, 'best_users_mean_popularity_min'] = np.min(best_users_mean_values_list)\n",
    "        df.at[index, 'best_users_median_popularity_dict'] = best_users_median_popularity_dict\n",
    "        df.at[index, 'best_users_median_popularity_mean'] = np.mean(best_users_median_values_list)\n",
    "        df.at[index, 'best_users_median_popularity_max'] = np.max(best_users_median_values_list)\n",
    "        df.at[index, 'best_users_median_popularity_min'] = np.min(best_users_median_values_list)\n",
    "        df.at[index, 'best_users_node_degree'] = best_users_node_degree_dict\n",
    "        df.at[index, 'best_users_node_degree_mean'] = np.mean(best_users_node_degree_list)\n",
    "        df.at[index, 'best_users_node_degree_median'] = np.median(best_users_node_degree_list)\n",
    "        df.at[index, 'best_users_node_degree_min'] = np.min(best_users_node_degree_list)\n",
    "        df.at[index, 'best_users_node_degree_max'] = np.max(best_users_node_degree_list)\n",
    "\n",
    "        df.at[index, 'worst_users_mean_popularity_dict'] = worst_users_mean_popularity_dict\n",
    "        df.at[index, 'worst_users_mean_popularity_mean'] = np.mean(worst_users_mean_values_list)\n",
    "        df.at[index, 'worst_users_mean_popularity_max'] = np.max(worst_users_mean_values_list)\n",
    "        df.at[index, 'worst_users_mean_popularity_min'] = np.min(worst_users_mean_values_list)\n",
    "        df.at[index, 'worst_users_median_popularity_dict'] = worst_users_median_popularity_dict\n",
    "        df.at[index, 'worst_users_median_popularity_mean'] = np.mean(worst_users_median_values_list)\n",
    "        df.at[index, 'worst_users_median_popularity_max'] = np.max(worst_users_median_values_list)\n",
    "        df.at[index, 'worst_users_median_popularity_min'] = np.min(worst_users_median_values_list)\n",
    "        df.at[index, 'worst_users_node_degree'] = worst_users_node_degree_dict\n",
    "        df.at[index, 'worst_users_node_degree_mean'] = np.mean(worst_users_node_degree_list)\n",
    "        df.at[index, 'worst_users_node_degree_median'] = np.median(worst_users_node_degree_list)\n",
    "        df.at[index, 'worst_users_node_degree_min'] = np.min(worst_users_node_degree_list)\n",
    "        df.at[index, 'worst_users_node_degree_max'] = np.max(worst_users_node_degree_list)\n",
    "\n",
    "        df.at[index, 'all_users_mean_popularity_mean'] = np.mean(all_users_mean_values_list)\n",
    "        df.at[index, 'all_users_mean_popularity_max'] = np.max(all_users_mean_values_list)\n",
    "        df.at[index, 'all_users_mean_popularity_min'] = np.min(all_users_mean_values_list)\n",
    "        df.at[index, 'all_users_median_popularity_mean'] = np.mean(all_users_median_values_list)\n",
    "        df.at[index, 'all_users_median_popularity_max'] = np.max(all_users_median_values_list)\n",
    "        df.at[index, 'all_users_median_popularity_min'] = np.min(all_users_median_values_list)\n",
    "        df.at[index, 'all_users_node_degree_mean'] = all_users_node_degree_dict.mean()\n",
    "        df.at[index, 'all_users_median_node_degree_median'] = all_users_node_degree_dict.median()\n",
    "        df.at[index, 'all_users_node_degree_max'] = all_users_node_degree_dict.max()\n",
    "        df.at[index, 'all_users_node_degree_min'] = all_users_node_degree_dict.min()\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefbca002b3dbc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall_df = pd.read_csv('log/Benchmark/Overall-Benchmark.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33ffe108a93654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: takes approx. 2-3 min\n",
    "file_path = \"log/Dataset/user_classical_characteristics.csv\"\n",
    "if not os.path.isfile(file_path):\n",
    "    print(\"File does not exist, calculate all user's popularity for each dataset..\")\n",
    "    overall_df = get_user_popularity(overall_df, popularity_dict, num_rows = overall_df.shape[0])\n",
    "    overall_df.to_csv(file_path, sep='\\t', index=False)\n",
    "else:\n",
    "    print(f\"File exists! Load file from {file_path}\")\n",
    "    overall_df = pd.read_csv(file_path, sep='\\t')\n",
    "    overall_df = process_user_columns(overall_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3648ea94f91e21d8",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "- merge all processed data frames together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a5b892894f7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(dataset_characteristics, overall_df, on='dataset', how='inner')  # you can change how to 'left', 'right', or 'outer'\n",
    "merged_df = merged_df[merged_df['dataset'] != 177]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f2716c6b032d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot metrics by dataset with model averages\n",
    "def plot_metrics_by_dataset(df, metric, dataset_range=None, models=None, model_names=None, save_fig=False):\n",
    "    # Ensure the 'metric' column exists in the dataframe\n",
    "    if metric not in df.columns:\n",
    "        raise ValueError(f\"Metric '{metric}' not found in dataframe columns.\")\n",
    "    \n",
    "    if dataset_range:\n",
    "        lower_bound, upper_bound = dataset_range\n",
    "        df = df[(df['dataset'] >= lower_bound) & (df['dataset'] <= upper_bound)]\n",
    "\n",
    "    if model_names is None:\n",
    "        model_names = models\n",
    "    \n",
    "    # Check if models list is provided\n",
    "    if models:\n",
    "        # Filter DataFrame to include only specified models and set ordering\n",
    "        df = df[df['Model'].isin(models)]\n",
    "        df['Model'] = pd.Categorical(df['Model'], categories=model_names, ordered=True)\n",
    "\n",
    "    # Calculate average metric values for each model\n",
    "    model_averages = df.groupby('Model', observed=False)[metric].mean()\n",
    "\n",
    "    # Set global font size and padding\n",
    "    plt.rc('font', size=30)            \n",
    "    plt.rc('axes', titlesize=30, labelsize=30)\n",
    "    plt.rc('axes', labelpad=30) \n",
    "    plt.rc('xtick', labelsize=14)\n",
    "    plt.rc('ytick', labelsize=18) \n",
    "\n",
    "    # Define custom colors\n",
    "    tu_dd_blue = (0 / 255, 48 / 255, 93 / 255)\n",
    "    bu_green1 = (138 / 255, 203 / 255, 193 / 255)\n",
    "    bu_green2 = (0 / 255, 172 / 255, 169 / 255)\n",
    "    bu_green3 = (0 / 255, 131 / 255, 141 / 255)\n",
    "    ing_blue1 = (132 / 255, 207 / 255, 237 / 255)\n",
    "    ing_blue2 = (0 / 255, 161 / 255, 217 / 255)\n",
    "    ing_blue3 = (0 / 255, 119 / 255, 174 / 255)\n",
    "    ing_blue4 = (0 / 255, 105 / 255, 180 / 255)\n",
    "\n",
    "    colors = [tu_dd_blue, ing_blue4, bu_green1]\n",
    "    cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", colors, N=len(df['Model'].unique()))\n",
    "    palette = [cmap(i / (len(df['Model'].unique()) - 1)) for i in range(len(df['Model'].unique()))]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    lineplot = sns.lineplot(x='dataset', y=metric, hue='Model', data=df, marker='o', markersize=6, palette=palette)\n",
    "\n",
    "    # Retrieve the colors used for each model from the seaborn plot\n",
    "    handles, labels = lineplot.get_legend_handles_labels()\n",
    "    color_map = {label: handle.get_color() for label, handle in zip(labels, handles)}\n",
    "\n",
    "    # Add horizontal lines for model averages with the corresponding model color\n",
    "    for model, avg in model_averages.items():\n",
    "        plt.axhline(avg, linestyle='--', color=color_map[model])\n",
    "\n",
    "    # Customize plot\n",
    "    plt.xlabel('Dataset #')\n",
    "    plt.ylabel(\"\")\n",
    "    plt.legend(title='Model')\n",
    "    \n",
    "    # Resize and position legend\n",
    "    plt.legend(\n",
    "        title='Model',\n",
    "        title_fontsize=16,           # Font size for the legend title\n",
    "        fontsize=14,                 # Font size for the legend labels (text)\n",
    "        #bbox_to_anchor=(1.05, 1),  # Place legend to the right of the plot\n",
    "        loc='upper right',          # Align legend at the top-left relative to bbox\n",
    "        borderaxespad=0.5,         # Padding between legend and axes\n",
    "        markerscale=1.5,           # Scale marker size in legend\n",
    "        labelspacing=0.5,          # Space between legend entries\n",
    "        handlelength=2.0           # Length of legend line handles\n",
    "    )\n",
    "\n",
    "    if dataset_range and dataset_range[1] >= 176:\n",
    "        xticks = [1] + list(range(10, 176, 10)) + [176]\n",
    "        plt.xticks(xticks)  # Adjust step size (e.g., 10) for better label visibility\n",
    "\n",
    "    # Display grid\n",
    "    plt.grid(True)\n",
    "    \n",
    "    if save_fig:\n",
    "        plt.savefig(f\"../asset/plots/results_{metric}.png\", dpi=300, transparent=True)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e9e0cd7d20207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: Plot MR@10 and NDCG@10\n",
    "model_list = ['AsymKNNUser', 'ALS', 'XSimGCL']\n",
    "model_name_list = ['User-KNN', 'ALS', 'XSimGCL']\n",
    "plot_metrics_by_dataset(merged_df, \"ndcg@10\", dataset_range=[1,176], models=model_list, model_names=model_name_list, save_fig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c629c9f0bc0d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_by_dataset_with_boxplot(df, metric, dataset_range=None, models=None, model_names=None, save_fig = False):\n",
    "    # Ensure the 'metric' column exists in the dataframe\n",
    "    if metric not in df.columns:\n",
    "        raise ValueError(f\"Metric '{metric}' not found in dataframe columns.\")\n",
    "    \n",
    "    if dataset_range:\n",
    "        lower_bound, upper_bound = dataset_range\n",
    "        df = df[(df['dataset'] >= lower_bound) & (df['dataset'] <= upper_bound)]\n",
    "\n",
    "    if model_names is None:\n",
    "        model_names = models\n",
    "    \n",
    "    # Check if models list is provided\n",
    "    if models:\n",
    "        # Filter DataFrame to include only specified models and set ordering\n",
    "        df = df[df['Model'].isin(models)]\n",
    "        df['Model'] = pd.Categorical(df['Model'], categories=model_names, ordered=True)\n",
    "\n",
    "    # Set global font size and padding\n",
    "    plt.rc('font', size=30)            \n",
    "    plt.rc('axes', titlesize=30, labelsize=30)\n",
    "    plt.rc('axes', labelpad=30) \n",
    "    plt.rc('xtick', labelsize=16)\n",
    "    plt.rc('ytick', labelsize=18) \n",
    "\n",
    "    # Define custom colors\n",
    "    tu_dd_blue = (0 / 255, 48 / 255, 93 / 255)\n",
    "    bu_green1 = (138 / 255, 203 / 255, 193 / 255)\n",
    "    bu_green2 = (0 / 255, 172 / 255, 169 / 255)\n",
    "    bu_green3 = (0 / 255, 131 / 255, 141 / 255)\n",
    "    ing_blue1 = (132 / 255, 207 / 255, 237 / 255)\n",
    "    ing_blue2 = (0 / 255, 161 / 255, 217 / 255)\n",
    "    ing_blue3 = (0 / 255, 119 / 255, 174 / 255)\n",
    "    ing_blue4 = (0 / 255, 105 / 255, 180 / 255)\n",
    "\n",
    "    colors = [bu_green1, ing_blue1, ing_blue4]\n",
    "    cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", colors, N=len(df['Model'].unique()))\n",
    "    palette = [cmap(i / (len(df['Model'].unique()) - 1)) for i in range(len(df['Model'].unique()))]\n",
    "    \n",
    "    # Create the plot using seaborn boxplot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    boxplot = sns.boxplot(\n",
    "        x='Model', y=metric, data=df, showmeans=True, meanline=True, \n",
    "        meanprops={\"linestyle\": \"--\", \"color\": \"black\"}, \n",
    "        palette=palette, hue='Model', dodge=False, legend=False\n",
    "    )\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.xlabel(\"\")  # Turn off x-axis label\n",
    "    plt.ylabel(f'{metric}')\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_fig: plt.savefig(f\"../asset/plots/boxplot_{metric}.png\", dpi=300, transparent=True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a1853cffdcb861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: Plot MR@10 and NDCG@10\n",
    "model_list = ['Pop', 'AsymKNNUser', 'AsymKNNItem', 'ALS', 'BPR', 'NGCF', 'LightGCN', 'SGL', 'XSimGCL']\n",
    "model_name_list = ['Pop', 'AsymKNNUser', 'AsymKNNItem', 'ALS', 'BPR', 'NGCF', 'LightGCN', 'SGL', 'XSimGCL']\n",
    "plot_metrics_by_dataset_with_boxplot(merged_df, \"ndcg@10\", dataset_range=[1,176], models=model_list, model_names=model_name_list, save_fig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0016d9bd620a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_user_characteristics_per_dataset(df, metrics, dataset_range=None):\n",
    "    # Validate metrics list\n",
    "    valid_metrics = [\n",
    "        'best_users_mean_popularity_mean', 'best_users_median_popularity_mean',\n",
    "        'worst_users_mean_popularity_mean', 'worst_users_median_popularity_mean',\n",
    "        'best_users_node_degree_mean', 'best_users_node_degree_median',\n",
    "        'worst_users_node_degree_mean', 'worst_users_node_degree_median'\n",
    "    ]\n",
    "    for metric in metrics:\n",
    "        if metric not in valid_metrics:\n",
    "            raise ValueError(f\"Invalid metric '{metric}'. Choose a valid metric.\")\n",
    "\n",
    "    # Filter dataframe based on dataset range if provided\n",
    "    if dataset_range:\n",
    "        integer1, integer2 = dataset_range\n",
    "        df = df[(df['dataset'] >= integer1) & (df['dataset'] <= integer2)]\n",
    "\n",
    "    # Initialize plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Loop through each metric to plot\n",
    "    for metric in metrics:\n",
    "        # Ensure the metric column and min/max columns are numeric\n",
    "        df[metric] = pd.to_numeric(df[metric], errors='coerce')\n",
    "\n",
    "        # Check for missing or invalid values in the metric column\n",
    "        if df[metric].isnull().any():\n",
    "            raise ValueError(f\"The metric column '{metric}' contains NaN values, which are not allowed.\")\n",
    "\n",
    "        # Initialize min_value and max_value based on the metric\n",
    "        if metric == 'best_users_mean_popularity_mean':\n",
    "            min_value = 'best_users_mean_popularity_min'\n",
    "            max_value = 'best_users_mean_popularity_max'\n",
    "        elif metric == 'best_users_median_popularity_mean':\n",
    "            min_value = 'best_users_median_popularity_min'\n",
    "            max_value = 'best_users_median_popularity_max'\n",
    "        elif metric == 'worst_users_mean_popularity_mean':\n",
    "            min_value = 'worst_users_mean_popularity_min'\n",
    "            max_value = 'worst_users_mean_popularity_max'\n",
    "        elif metric == 'worst_users_median_popularity_mean':\n",
    "            min_value = 'worst_users_median_popularity_min'\n",
    "            max_value = 'worst_users_median_popularity_max'\n",
    "        elif metric in ['best_users_node_degree_mean', 'best_users_node_degree_median']:\n",
    "            min_value = 'best_users_node_degree_min'\n",
    "            max_value = 'best_users_node_degree_max'\n",
    "        elif metric in ['worst_users_node_degree_mean', 'worst_users_node_degree_median']:\n",
    "            min_value = 'worst_users_node_degree_min'\n",
    "            max_value = 'worst_users_node_degree_max'\n",
    "\n",
    "        # Ensure the min/max columns are numeric\n",
    "        df[min_value] = pd.to_numeric(df[min_value], errors='coerce')\n",
    "        df[max_value] = pd.to_numeric(df[max_value], errors='coerce')\n",
    "\n",
    "\n",
    "        # Plot the selected metric\n",
    "        sns.lineplot(x='dataset', \n",
    "                     y=metric, \n",
    "                     data=df, \n",
    "                     marker='o', \n",
    "                     markersize=4, \n",
    "                     errorbar=lambda x: (x.min(), x.max()),\n",
    "                     label=metric.replace('_', ' ').title())\n",
    "\n",
    "\n",
    "    # Customize plot\n",
    "    plt.xlabel('Dataset #')\n",
    "    plt.ylabel(\"\")\n",
    "\n",
    "    # Resize and position legend\n",
    "    plt.legend(\n",
    "        title='Metrics',\n",
    "        title_fontsize=16,           # Font size for the legend title\n",
    "        fontsize=14,                 # Font size for the legend labels (text)\n",
    "        loc='upper right',          # Align legend at the top-right relative to bbox\n",
    "        borderaxespad=0.5,         # Padding between legend and axes\n",
    "        markerscale=1.5,           # Scale marker size in legend\n",
    "        labelspacing=0.5,          # Space between legend entries\n",
    "        handlelength=2.0           # Length of legend line handles\n",
    "    )\n",
    "\n",
    "    # Adjust x-axis ticks based on the dataset range if necessary\n",
    "    if dataset_range and dataset_range[1] >= 176:\n",
    "        xticks = [1] + list(range(15, 176, 10)) + [176]\n",
    "        plt.xticks(xticks)  # Adjust step size (e.g., 10) for better label visibility\n",
    "\n",
    "    # Display grid\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd92fc7d691cc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_user_characteristics_per_dataset(merged_df, metrics=['best_users_mean_popularity_mean', 'worst_users_mean_popularity_mean'], dataset_range=[1,176])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cf909073169179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression(df, models, dataset_range=None, model_names=None, metric='best_users_mean_popularity_mean', target_metric='ndgc@10', transformation='log'):\n",
    "    # Ensure the metric exists in the dataframe\n",
    "    if metric not in df.columns:\n",
    "        raise ValueError(f\"Metric '{metric}' not found in dataframe columns.\")\n",
    "    \n",
    "    # Extract metric values and the target metric values\n",
    "    metric_values = df[metric].dropna()  # Avoid NaNs in the metric\n",
    "    target_values = df[target_metric].dropna()  # Avoid NaNs in the target metric\n",
    "    \n",
    "    if len(metric_values) == 0 or len(target_values) == 0:\n",
    "        raise ValueError(f\"No valid data found for the regression between '{metric}' and '{target_metric}'.\")\n",
    "\n",
    "    # Filter the dataframe by the dataset range if provided\n",
    "    if dataset_range:\n",
    "        lower_bound, upper_bound = dataset_range\n",
    "        df = df[(df['dataset'] >= lower_bound) & (df['dataset'] <= upper_bound)]\n",
    "\n",
    "    # Set model names if not provided\n",
    "    if model_names is None:\n",
    "        model_names = models\n",
    "\n",
    "    # Ensure models are provided and filter the dataframe accordingly\n",
    "    if models:\n",
    "        df = df[df['Model'].isin(models)]  # Filter by the models in the 'models' list\n",
    "        df['Model'] = pd.Categorical(df['Model'], categories=model_names, ordered=True)  # Set model categories\n",
    "\n",
    "    # Prepare a plot for each model\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    for model_name in model_names:\n",
    "        model_df = df[df['Model'] == model_name]  # Filter for the current model\n",
    "\n",
    "        # Extract metric values and target values for the current model\n",
    "        model_metric_values = pd.to_numeric(model_df[metric].dropna())\n",
    "        model_target_values = pd.to_numeric(model_df[target_metric].dropna())\n",
    "\n",
    "        if len(model_metric_values) == 0 or len(model_target_values) == 0:\n",
    "            continue  # Skip this model if no valid data points are found\n",
    "\n",
    "        # Apply data transformation if needed\n",
    "        if transformation == 'log':\n",
    "            # Apply log transformation (ensure no zero or negative values)\n",
    "            model_metric_values = np.log1p(model_metric_values)\n",
    "        elif transformation == 'sqrt':\n",
    "            # Apply square root transformation (ensure no negative values)\n",
    "            model_metric_values = np.sqrt(model_metric_values)\n",
    "        \n",
    "        # Ensure the metric and target have matching valid data points\n",
    "        model_combined_df = pd.DataFrame({metric: model_metric_values, target_metric: model_target_values})\n",
    "        model_combined_df = model_combined_df.dropna()\n",
    "\n",
    "        # Perform linear regression for the current model\n",
    "        X = model_combined_df[[metric]].values.reshape(-1, 1)  # Features (metric)\n",
    "        y = model_combined_df[target_metric].values  # Target (e.g., ndgc@10)\n",
    "\n",
    "        # Perform linear regression\n",
    "        model_reg = LinearRegression()\n",
    "        model_reg.fit(X, y)\n",
    "\n",
    "        # Predictions from the model\n",
    "        y_pred = model_reg.predict(X)\n",
    "\n",
    "        # Scatter plot of the data for this model\n",
    "        sns.scatterplot(x=model_combined_df[metric], y=model_combined_df[target_metric], label=f'{model_name} Data', s=100)\n",
    "\n",
    "        # Plot the regression line for this model\n",
    "        plt.plot(model_combined_df[metric], y_pred, label=f'{model_name} Regression Line', linewidth=2)\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.xlabel(f'{metric}')\n",
    "    plt.ylabel(f'{target_metric}')\n",
    "    plt.legend()\n",
    "\n",
    "    # Display grid\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    return model_reg.coef_, model_reg.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1189111256336ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regression(example, models=['LightGCN'], dataset_range=[1,176], metric='best_users_mean_popularity_mean', target_metric='ndcg@10', transformation='sqrt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bfcd186e2fd1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(df, models, dataset_range=None, model_names=None, metrics=['best_users_mean_popularity_mean'], target_metrics=['ndgc@10'], transformation='log'):\n",
    "    # Ensure the metric exists in the dataframe\n",
    "    if target_metrics is None:\n",
    "        target_metrics = [col for col in df.columns if col.endswith('@10')]\n",
    "    \n",
    "    # Extract metric values and the target metric values\n",
    "    metric_values = df[metrics].dropna()  # Avoid NaNs in the metric\n",
    "    target_values = df[target_metrics].dropna()  # Avoid NaNs in the target metric\n",
    "    \n",
    "    # Filter the dataframe by the dataset range if provided\n",
    "    if dataset_range:\n",
    "        lower_bound, upper_bound = dataset_range\n",
    "        df = df[(df['dataset'] >= lower_bound) & (df['dataset'] <= upper_bound)]\n",
    "\n",
    "    # Set model names if not provided\n",
    "    if model_names is None:\n",
    "        model_names = models\n",
    "\n",
    "    # Ensure models are provided and filter the dataframe accordingly\n",
    "    if models:\n",
    "        df = df[df['Model'].isin(models)]  # Filter by the models in the 'models' list\n",
    "        df['Model'] = pd.Categorical(df['Model'], categories=model_names, ordered=True)  # Set model categories\n",
    "\n",
    "    # Set global font size and padding\n",
    "    plt.rc('font', size=12)            \n",
    "    plt.rc('axes', titlesize=30, labelsize=30)\n",
    "    plt.rc('axes', labelpad=10) \n",
    "    plt.rc('xtick', labelsize=12)\n",
    "    plt.rc('ytick', labelsize=12) \n",
    "\n",
    "    # Define custom colors\n",
    "    tu_dd_blue = (0 / 255, 48 / 255, 93 / 255)\n",
    "    bu_green1 = (138 / 255, 203 / 255, 193 / 255)\n",
    "    bu_green2 = (0 / 255, 172 / 255, 169 / 255)\n",
    "    bu_green3 = (0 / 255, 131 / 255, 141 / 255)\n",
    "    ing_blue1 = (132 / 255, 207 / 255, 237 / 255)\n",
    "    ing_blue2 = (0 / 255, 161 / 255, 217 / 255)\n",
    "    ing_blue3 = (0 / 255, 119 / 255, 174 / 255)\n",
    "    ing_blue4 = (0 / 255, 105 / 255, 180 / 255)\n",
    "\n",
    "    colors = [bu_green1, ing_blue4, tu_dd_blue]\n",
    "    cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", colors)\n",
    "\n",
    "    # Prepare a plot for each model\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    for model_name in model_names:\n",
    "        model_df = df[df['Model'] == model_name].reset_index()  # Filter for the current model\n",
    "\n",
    "        # Extract metric values and target values for the current model\n",
    "        model_metric_values = model_df[metrics].apply(pd.to_numeric)\n",
    "        model_target_values = model_df[target_metrics].apply(pd.to_numeric)\n",
    "\n",
    "        if len(model_metric_values) == 0 or len(model_target_values) == 0:\n",
    "            continue  # Skip this model if no valid data points are found\n",
    "\n",
    "        # Apply data transformation if needed\n",
    "        if transformation == 'log':\n",
    "            # Apply log transformation (ensure no zero or negative values)\n",
    "            model_metric_values = model_metric_values.apply(np.log1p)\n",
    "        elif transformation == 'sqrt':\n",
    "            # Apply square root transformation (ensure no negative values)\n",
    "            model_metric_values =  model_metric_values.apply(np.sqrt)\n",
    "\n",
    "        correlation_data = pd.concat([model_metric_values, model_target_values], axis=1)\n",
    "    \n",
    "        # Compute the correlation matrix\n",
    "        correlation_matrix = correlation_data.corr()\n",
    "    \n",
    "        # Plot the heatmap\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap=cmap, center=0, fmt='.3f', linewidths=0.5)\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98a678ad7f0f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_matrix(example, models=['LightGCN'], dataset_range=[1,176], metrics=['best_users_mean_popularity_mean'], target_metrics=None,  transformation='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dad7fa08a59adc9",
   "metadata": {},
   "source": [
    "#### For Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33034f09b474e715",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(model=\"BPR\", dataset=\"real-life-atomic-100000-1\", config_file_list=[\"config_files/datasets.yaml\"])\n",
    "dataset = create_dataset(config)\n",
    "original_dict = dataset.field2token_id['user_id']\n",
    "flipped_dict = {v: k for k, v in dataset.field2token_id['user_id'].items()}\n",
    "\n",
    "#print(original_dict)\n",
    "print(flipped_dict[937])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1250f398d385e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = PROJECT_DIRECTORY / f\"asset/data/real-life-atomic-splits/real-life-atomic-100000-{1}/real-life-atomic-100000-{1}.inter\"\n",
    "db = pd.read_csv(FILENAME, sep=\"\\t\", encoding=\"utf-8\")\n",
    "\n",
    "# Filter users with less than 20 interactions\n",
    "db['interaction_count'] = db.groupby(\"userID:token\")[\"itemID:token\"].transform('count')\n",
    "filtered_df = db[db['interaction_count'] >= 20].copy()\n",
    "all_users_interactions_dict = filtered_df.groupby(\"userID:token\")['interaction_count'].first()\n",
    "\n",
    "print(all_users_interactions_dict[896])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3df9a1140dc00e",
   "metadata": {},
   "source": [
    "#### Statistical Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6786fa684b92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance_test(df, characteristics, models, metrics, apply_log = True):\n",
    "    # Center the data (subtract the mean of each feature)\n",
    "    data = df[df['Model'].isin(models)].reset_index(drop=True).copy()\n",
    "    sanitized_columns = {col: col.split('@')[0] for col in df.columns}\n",
    "    data = data.rename(columns=sanitized_columns)\n",
    "    \n",
    "    data[characteristics] = data[characteristics].apply(pd.to_numeric)\n",
    "    data[metrics] = data[metrics].apply(pd.to_numeric)\n",
    "\n",
    "    if apply_log:\n",
    "        log_characteristics = [characteristic for characteristic in characteristics if not characteristic.startswith('degree')]\n",
    "        data[log_characteristics] = data[log_characteristics].apply(np.log10)\n",
    "\n",
    "    data[characteristics] = data[characteristics].apply(lambda x: x - x.mean())\n",
    "\n",
    "\n",
    "    # Iterate over the metrics to create the new columns\n",
    "    df_new = pd.DataFrame()\n",
    "    \n",
    "    for model in models:\n",
    "        for metric in metrics:\n",
    "            df_new[f\"{model}_{metric}\"] = data[data['Model']==model][metric].reset_index(drop=True)\n",
    "        for characteristic in characteristics:\n",
    "            df_new[characteristic] = data[data['Model']==model][characteristic].reset_index(drop=True)\n",
    "\n",
    "    # Randomly split data into training and test sets (90% training, 10% test)\n",
    "    #msk = np.random.rand(len(df_new)) < 0.9\n",
    "    #test = df_new[~msk]\n",
    "    train = df_new\n",
    "\n",
    "    # List to store the regression results\n",
    "    models_results = []\n",
    "\n",
    "    # Iterate over each metric\n",
    "    for metric in metrics:\n",
    "        # Iterate over each model\n",
    "        for idx, model in enumerate(models):\n",
    "            X = train[characteristics]\n",
    "            y = train[model + '_' + metric]  # Use the newly created column\n",
    "            \n",
    "            # Define the formula for OLS regression\n",
    "            formula_str_ml = y.name + ' ~ ' + '+'.join(characteristics)\n",
    "            \n",
    "            # Perform OLS regression using statsmodels\n",
    "            model_ml = sm.ols(formula=formula_str_ml, data=train[characteristics+[model + '_' + metric]])\n",
    "            fitted_ml = model_ml.fit(cov_type='HC1')  # Robust standard errors (HC1)\n",
    "\n",
    "            print(fitted_ml.summary())\n",
    "            print(\"Parameters: \", fitted_ml.params)\n",
    "            print(\"R2: \", fitted_ml.rsquared)\n",
    "            \n",
    "            # Append the results to models_results\n",
    "            models_results.append({\n",
    "                'model': model,\n",
    "                'metric': metric,\n",
    "                'score': fitted_ml.rsquared,\n",
    "                'adjusted_score': fitted_ml.rsquared_adj,\n",
    "                **fitted_ml.params.to_dict(),  # Coefficients\n",
    "                **fitted_ml.pvalues.rename(lambda x: 'p_' + x).to_dict()  # p-values\n",
    "            })\n",
    "\n",
    "            pred_ols = fitted_ml.get_prediction()\n",
    "            iv_l = pred_ols.summary_frame()[\"obs_ci_lower\"]\n",
    "            iv_u = pred_ols.summary_frame()[\"obs_ci_upper\"]\n",
    "\n",
    "            assert len(iv_l) == len(X), f\"Length of 'iv_l' ({len(iv_l)}) does not match length of X ({len(X)})\"\n",
    "\n",
    "            if X.shape[1] == 1:\n",
    "                fig, ax = plt.subplots(figsize=(8, 6))\n",
    "                ax.plot(X, y, \"o\", label=\"data\")\n",
    "                ax.plot(X, fitted_ml.fittedvalues, \"r--.\", label=\"OLS\")\n",
    "                ax.plot(X, iv_u, \"r--\")\n",
    "                ax.plot(X, iv_l, \"r--\")\n",
    "                ax.legend(loc=\"best\")\n",
    "            \n",
    "        # Convert the results to a DataFrame\n",
    "        df_results = pd.DataFrame.from_dict(models_results)\n",
    "    \n",
    "        df_results.to_csv(f\"../eval/log/dataset/significance_test_{metric}.csv\", sep='\\t', index=None)\n",
    "    \n",
    "    # Regression plots: https://www.statsmodels.org/dev/examples/notebooks/generated/regression_plots.html\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "df = pd.read_csv('myFile', delim_whitespace = True, header = None)\n",
    "df.columns = ['column1', 'column2']\n",
    "y, X = ps.dmatrices('column1 ~ column2',data = df, return_type = 'dataframe')\n",
    "model = sm.OLS(y,X)\n",
    "results = model.fit()\n",
    "predictedValues = results.predict()\n",
    "#print predictedValues\n",
    "yData = df.as_matrix(columns = ['column1'])\n",
    "res = yData - predictedValues"
   ],
   "id": "1416a19d770c21a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f91e826235906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df.keys()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360b2384456abfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Define your characteristics, models, and metrics\n",
    "characteristics = ['best_users_mean_popularity_mean', 'degree_assort_user', 'average_degree', 'gini_user']\n",
    "# same characteristics as in https://dl.acm.org/doi/pdf/10.1145/3640457.3688070\n",
    "characteristics = ['space_size', 'shape', 'density', 'gini_user', 'gini_item', 'average_degree_user', 'average_degree_item', 'average_clustering_coef_dot_user', 'average_clustering_coef_dot_item', 'degree_assort_user', 'degree_assort_item']\n",
    "characteristics = ['space_size', 'shape', 'density', 'gini_user', 'gini_item', 'average_degree_user', 'average_degree_item', 'average_clustering_coef_dot_user', 'average_clustering_coef_dot_item', 'degree_assort_item']\n",
    "\n",
    "models = ['LightGCN']\n",
    "metrics = ['ndcg']\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "significance_test(merged_df, characteristics, models, metrics, apply_log=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
